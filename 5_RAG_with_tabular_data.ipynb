{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(load_dotenv())  # Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Client\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=str(here(\"data/chroma\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection in ChromaDB\n",
    "collection_name = \"titanic_small\"\n",
    "collection = chroma_client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "file_dir = here(\"data/for_upload/titanic_small.csv\")\n",
    "df = pd.read_csv(file_dir, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare documents, metadata, and embeddings\n",
    "docs, metadatas, ids, embeddings = [], [], [], []\n",
    "for index, row in df.iterrows():\n",
    "    output_str = \"\\n\".join([f\"{col}: {row[col]}\" for col in df.columns]) + \"\\n\"\n",
    "\n",
    "    # Generate text embedding\n",
    "    response = client.embeddings.create(\n",
    "        input=output_str,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    \n",
    "    # Store data for ChromaDB\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "    docs.append(output_str)\n",
    "    metadatas.append({\"source\": collection_name})\n",
    "    ids.append(f\"id{index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to ChromaDB\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in vectordb: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vectors in vectordb:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query a text string\n",
    "query_text = \"what's the average age of survivors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate query embedding\n",
    "response = client.embeddings.create(\n",
    "    input=query_text,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant documents\n",
    "vectordb = chroma_client.get_collection(name=collection_name)\n",
    "results = vectordb.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=1  # top_k results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prompt for GPT model\n",
    "system_role = \"You will receive the user's question along with search results from a database. Provide the best possible answer.\"\n",
    "prompt = f\"User's question: {query_text} \\n\\nSearch results:\\n{results}\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_role},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate response using GPT-4 Turbo\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The search results provided only include information about one individual survivor, Mrs. John Bradley (Florence Briggs Thayer) Cumings, and her age was 38. To obtain the average age of all survivors, information about the ages of all other survivors would be necessary. Based on the data provided, it is only possible to state the age of this one survivor. If you are looking for a comprehensive average, please provide more details or data on other survivors.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex  Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male   22                        1                        0   7.2500  \n",
       "1  female   38                        1                        0  71.2833  \n",
       "2  female   26                        0                        0   7.9250  \n",
       "3  female   35                        1                        0  53.1000  \n",
       "4    male   35                        0                        0   8.0500  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up the collection data (delete collection)\n",
    "# chroma_client.delete_collection(name=collection_name)\n",
    "# print(f\"Collection '{collection_name}' deleted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'titanic_small' deleted successfully.\n",
      "Error retrieving collection after deletion: Collection titanic_small does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Clean up the collection data (delete collection)\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting collection: {e}\")\n",
    "\n",
    "# Verify collection deletion\n",
    "try:\n",
    "    # Try to retrieve the collection after deletion\n",
    "    chroma_client.get_collection(name=collection_name)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving collection after deletion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_small'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
